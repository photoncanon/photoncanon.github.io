<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<!-- saved from url=(0031)-->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<meta name="keywords" content="Zhe Wang, 王哲, Electronic Engineering, The Chinese University of Hong Kong, Zhejiang University">
<meta name="description" content="ZWANG">
<link rel="stylesheet" href="./welcome_files/jemdoc.css" type="text/css">
<link rel="shortcut icon" href="./welcome_files/zwang2018.jpg" width="263px" height="300px">
<title>Wang Zhe</title>
<style type="text/css"></style>

<script type="text/javascript" src="./welcome_files/jquery.min.js"></script></head>
<body>
<div id="layout-content">
<p>


<script type="text/javascript" async="" src="./welcome_files/map.js"></script><script type="text/javascript">
<!--
    function toggleBibtex(articleid) {
  var bib = document.getElementById(articleid);
    if(bib.style.display == "none") {
      bib.style.display = "";
    }
    else {
      bib.style.display = "none";
    }
}
-->
</script>
</p>

<table class="imgtable"><tbody><tr>
<td width="600" align="left">
<div id="toptitle"> 
  <h1><a href="http://www.ee.cuhk.edu.hk/~zwang/welcome.html">Wang Zhe</a> &nbsp; 王哲</h1>
</div>
<p>

Email: <a href="mailto:wangzhe@sensetime.com">wangzhe at sensetime dot com</a><br><br>
Address: Room 226, Core Building No.2, Hong Kong Science Park. <br>
Shatin, New Territory, Hong Kong <br><br>

<a href="https://scholar.google.com.hk/citations?user=546GPMoAAAAJ&hl=zh-CN">Google Scholar</a> &middot <a href="https://www.linkedin.com/home?trk=nav_responsive_tab_home">LinkedIn</a> &middot <a href="./welcome_files/cv/resume_cv.pdf">My resume</a> (last updated at 2020.9)<br>
<p></p>
</td>
<td align="left">
<img src="./welcome_files/zwang2018.jpg" alt="" width="360px" height="270px"> &nbsp;</td>

</tr>
</tbody></table>

<h2>  Short Bio </h2>
<ul>
<li><p>
    Currently I am a Research Vice Director in the autonomous driving R&D team at SenseTime. I lead the lidar peception team, who is responsible for developing accurate and reliable perception systems for autonomous driving, or more generally speaking, Intelligent Traffic Systems. 
    We are mainly focusing on Lidar based perception,  multiple object tracking and sensor fusion. We are also interested in vavious challenges in autonomous driving, such as mapping and localization, monocular/stereo 3D object detection, and video analysis.  
  
  
    I am now recuiting self-motivated interns / full-time researchers or developers with strong machine learning background and programming skills. If you are interested, please send your CV to my Email (wangzhe@sensetime.com) </p></li>
<li><p>
    I obtained my Ph.D. degree from EE department of CUHK in 2017, supervised by <a href="http://www.ee.cuhk.edu.hk/~xgwang/"> Professor Xiaogang Wang </a>. I was both in <a href="http://http://ivp.ee.cuhk.edu.hk//">IVP lab</a> and <a href="http://mmlab.ie.cuhk.edu.hk/"> Multimedia Lab</a>. 
</p></li>
<li><p>
    Before I came to CUHK, I received a Bachelor's degree from <a href="http://en.sist.ustc.edu.cn/Departments/201105/t20110520_111931.html"> the department of Optical Engineering </a> of <a href="http://en.ustc.edu.cn/"> Zhejiang University (ZJU) </a> in July 2012. 
</p></li>

</ul>


<h2>  Research Interests </h2>
<ul>
  Computer Vision, Deep Learning, Medical Imaging
</ul>


<h2>  News </h2>
<ul>
  <img alt="" height="30" src="./welcome_files/new.gif" width="30"/>Our TCSVT 2017 paper "T-CNN: Tubelets With Convolutional Neural Networks for Object Detection From Videos", has been selected to receive the 2020 Outstanding Young Author Award by the CAS Society, 2020. </a> 
</ul>
<ul>
  <img alt="" height="30" src="./welcome_files/new.gif" width="30"/>One paper accepted by TPAMI. </a> 
</ul>
<ul>
  <img alt="" height="30" src="./welcome_files/new.gif" width="30"/>Two papers accepted by CVPR 2020. </a> 
  Our methods achieve new state-of-the-art in Lidar based (PV-RCNN) and camera based (D^4-LCN) 3D object detection on KITTI benchmark, respectively. Congrats to Shaoshuai and Mingyu!
</ul>
<ul>
  <img alt="" height="30" src="./welcome_files/new.gif" width="30"/>One paper accepted by AAAI 2020. </a>
</ul>
<ul>
<img alt="" height="30" src="./welcome_files/new.gif" width="30"/>One journal paper accepted by CVIU. </a>
</ul>
<ul>
<img alt="" height="30" src="./welcome_files/new.gif" width="30"/>Two papers accepted by ICCV 2019. </a>
</ul>


<h2>Competitions</h2>
<ul>
	<li>
		<font size="4"><b>No. 1</b> in DAVIS Challenge on Video Object Segmentation 2017. <a href="https://github.com/lxx1991/VS-ReID">[code]</a></font> <a href="https://liuziwei7.github.io/projects/VSReID.html">[project]</a>
	</li>
	<li>
		<font size="4"><b>No. 1</b> in ImageNet Object Detection Challenge 2016. <a href="./welcome_files/Poster_ImageNet_DeepID2.pdf">poster</a></font>
	</li>
	<li>
		<font size="4"><b>No. 1</b> in ImageNet Object Detection from Video Challenge 2015. <a href="./welcome_files/CUvideo_poster.pdf">poster</a> | <a href="./welcome_files/CUvideo_slides.pdf">slides</a></font>
	</li>
	<li>
		<font size="4"><b>No. 2</b> in ImageNet Object Detection Challenge 2015. <a href="./welcome_files/CUimage_poster.pdf">poster</a></font>
	</li>
	<li>
		<font size="4"><b>No. 2</b> in ImageNet Object Detection Challenge 2014. <a href="./welcome_files/CUHK_DeepID_Net_slides.ppsx">slides</a> </font>
	</li>

</ul>




<h2> Publications <a href="https://scholar.google.com.hk/citations?user=546GPMoAAAAJ&hl=zh-CN">[Google Scholar]</a></h2>

<ul>
  <li><p>Shaoshuai Shi, Chaoxu Guo, Li Jiang, <b>Zhe Wang</b>, Jianping Shi, Xiaogang Wang, Hongsheng Li,
  <a>"PV-RCNN: Point-Voxel Feature Set Abstraction for 3D Object Detection"</a>,  IEEE Conference on Computer Vision and Pattern Recognition, (CVPR), 2020 <a href="https://github.com/sshaoshuai/PV-RCNN">[code]</a></p> 
  <font color="red"> Ranks 1st on KITTI 3D object detection benchmark on Jan. 9th, 2020</font> <br /> 
</li>
</ul>


<ul>
  <li><p>Mingyu Ding, Yuqi Huo, Hongwei Yi, <b>Zhe Wang</b>, Jianping Shi, Zhiwu Lu, Ping Luo,
  <a>"Learning Depth-Guided Convolutions for Monocular 3D Object Detection"</a>,  IEEE Conference on Computer Vision and Pattern Recognition, (CVPR), 2020
  </p>
  <font color="red"> Ranks 1st on KITTI monocular 3D object detection benchmark on Nov. 11th, 2019</font> <br />
  </li>
</ul>


<ul>
  <li><p>Shaoshuai Shi, <b>Zhe Wang</b>, Xiaogang Wang, Hongsheng Li,
  <a>"From Points to Parts: 3D Object Detection from Point Cloud with Part-aware and Part-aggregation Network"</a>,  IEEE Transactions on Pattern Analysis and Machine Intelligence, (TPAMI), 2020 <a href="https://github.com/sshaoshuai/PCDet">[code]</a></p>
  <font color="red"> Ranks 1st on KITTI 3D object detection benchmark on July. 9th, 2019</font> <br />  
</li>
</ul>



<ul>
  <li><p>Hongwei Yi, Shaoshuai Shi, Mingyu Ding, Jiankai Sun, Hui Zhou, <b>Zhe Wang</b>, Sheng Li, Guoping Wang,
  <a>"SegVoxelNet: Exploring Semantic Context and Depth-aware Features for 3D Vehicle Detection from Point Cloud"</a>,  International Conference on Robotics and Automation (ICRA), 2020
  </p>
  </li>
</ul>


<ul>
  <li><p>Mingyu Ding, <b>Zhe Wang</b>, Bolei Zhou, Jianping Shi, Zhiwu Lu, Ping Luo,
  <a>"Every Frame Counts: Joint Learning of Video Segmentation and Optical Flow"</a>,  Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI), 2020
  </p>
  </li>
</ul>



<ul>
<li><p>Mingyu Ding, <b>Zhe Wang</b>, Zhiwu Lu,
<a>"Iteratively Optimized Semantic Autoencoder for Transductive Zero-shot Learning"</a>,  Computer Vision and Image Understanding (CVIU), 2019
</p>
</li>
</ul>

<ul>
<li><p>Wenwei Zhang, Hui Zhou, Shuyang Sun, <b>Zhe Wang</b>, Jianping Shi, Chen Change Loy,
<a>"Robust Multi Modality Multi-Object Tracking"</a>,  International Conference in Computer Vision (ICCV), 2019
</p>
</li>
</ul>


<ul>
<li><p>Mingyu Ding, <b>Zhe Wang</b>, Jiankai Sun, Jianping Shi, Ping Luo,
<a>"CamNet: Coarse-to-Fine Retrival for Camera Relocalization"</a>,  International Conference in Computer Vision (ICCV), 2019 <a href="https://github.com/dingmyu/CamNet">[code]</a>
</p>
</li>
</ul>


<ul>
<li><p>Yunhe Gao, Rui Huang, Ming Chen, <b>Zhe Wang</b>, Jincheng Deng, Yuanyuan Chen, Jie Zhang, Chanjuan Tao, and Hongsheng Li,
<a>"FocusNet: Imbalanced Large and Small Organ Segmentation with an End-to-End Deep Neural Network for Head and Neck CT Images"</a>,  International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2019
</p>
</li>
</ul>

<ul>
<li><p>Zhanyu Wang, <b>Zhe Wang</b>, Guoxiang Qu, Fei Li, Ye Yuan, Dennis SC Lam, Xiulan Zhang, Yu Qiao,
<a>"Intelligent Glaucoma Diagnosis via Active Learning and Adversarial Data Augmentation"</a>, IEEE International Symposium on Biomedical Imaging (ISBI), 2019.
</p>
</li>
</ul>



<ul>
<li><p>Kui Xu, <b>Zhe Wang</b>, Jianping Shi, Hongsheng Li, Qiangfeng Cliff Zhang,
<a href="./welcome_files/papers/aaai19-xk.pdf">"A^2-Net: Molecular Structure Estimation from Cryo-EM Density Volumes"</a>, The Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19). <i><b>(spotlight)</b></i>
</p>
</li>
</ul>

<ul>
<li><p>Fei Li, <b>Zhe Wang</b>, Guoxiang Qu, Diping Song, Ye Yuan, Yang Xu, Kai Gao, Guangwei Luo, Zegu Xiao, Dennis SC Lam, Hua Zhong, Yu Qiao, Xiulan Zhang
<a href="https://bmcmedimaging.biomedcentral.com/articles/10.1186/s12880-018-0273-5">"Automatic differentiation of Glaucoma visual field from non-glaucoma visual filed using deep convolutional neural network"</a>, BMC medical imaging.
</p>
</li>
</ul>


<ul>
<li><p>G. Qu*, W. Zhang*, <b>Z. Wang*</b>, X. Dai, J. Shi, J. He, F. Lei, X. Zhang, Y. Qiao,
<a href="./welcome_files/papers/stripnet-topology-consistent_1xz.pdf">"StripNet: Towards Topology Consistent Strip Structure Segmentation"</a>, ACM Multimedia Conference (ACM-MM), 2018. <i>(*equal contribution)</i>
</p>
</li>
</ul>

<ul>
<li><p>C. Yang, <b>Z. Wang</b>, X. Zhu, C. Huang, J. Shi, D. Lin,
<a href="./welcome_files/papers/pose_guided.pdf">"Pose Guided Human Video Generation"</a>, European Conference on Computer Vision (ECCV), 2018. 
</p>
</li>
</ul>

<ul>
<li><p>S. Chen, <b>Z. Wang</b>, J. Shi, B. Liu, N. Yu,
<a href="./welcome_files/papers/isbi_final.pdf">"A Multi-task Framework with Feature Passing Module for Skin Lesion Classification and Segmentation"</a>, IEEE International Symposium on Biomedical Imaging (ISBI),  2018.
</p>
</li>
</ul>

<ul>
<li><p>X. Li, Y. Qi, <b>Z. Wang</b>, K. Chen, Z. Liu, J. Shi, P. Luo, C. Change Loy, X. Tang,
<a href="./welcome_files/papers/DAVIS-Challenge-1st-Team.pdf">"Video Object Segmentation with Re-identification"</a>, The 2017 DAVIS Challenge on Video Object Segmentation - CVPR Workshops (<b>1st place</b>), 2017. 
</p>
</li>
</ul>


<ul>
<li><p><b>Zhe Wang</b>, Yanxin Yin, Jianping Shi, Wei Fang, Hongsheng Li, Xiaogang Wang,
<a href="./welcome_files/papers/zoominnet.pdf">"Zoom-in-Net: Deep Mining Lesions for Diabetic Retinopathy Detection"</a>, International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2017. 
</p>
</li>
</ul>

<ul>
<li><p>K. Kang, J. Yan, X. Zeng, B. Yang, T. Xiao, C. Zhang, <b>Z. Wang</b>, R. Wang, X. Wang, W. Ouyang. 
<a href="./welcome_files/papers/kangLYZ_tubelets.pdf">"T-CNN: Tubelets with Convolutional Neural Networks for Object Detection from Videos"</a>, IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2017.
</p>
</li>
</ul>

<ul>
<li><p>W. Ouyang, X. Zeng, X. Wang, S. Qiu, P. Luo, Y. Tian, H. Li, S. Yang, <b>Zhe Wang</b>, et al.
<a href="./welcome_files/papers/ouyangZWpami16.pdf">"DeepID-Net: Object Detection with Deformable Part Based Convolutional Neural Networks"</a>, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017.
</p>
</ul>

<ul>
<li><p><b>Zhe Wang</b>, H. Li, W. Ouyang, X. Wang. 
<a href="./welcome_files/papers/guidedsupervision.pdf">"Deep Representations for Scene Labeling with Semantic Context Guided
Supervision"</a>, arXiv preprint:1706.02493, 2017.
</p>
</li>
</ul>


<ul>
<li><p>X. Zeng, W. Ouyang, J. Yan, H. Li, T. Xiao, K. Wang, Y. Liu, Y. Zhou, B. Yang, <b>Zhe Wang</b>, H. Zhou, X. Wang. 
<a href="./welcome_files/papers/xyzeng_window-object.pdf">"Crafting GBD-Net for Object Detection"</a>, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017. (new)
</p>
</li>
</ul>

<ul>
<li><p><b>Zhe Wang</b>, H. Li, W. Ouyang, X. Wang.
<a href="./welcome_files/papers/learnable_histogram.pdf">"Learnable Histogram: Statistical Context Features for Deep Neural Networks"</a>, European Conference on Computer Vision (ECCV), 2016. <a href="./welcome_files/P-1A-15.pdf">(poster)</a>
</p></li>
</ul>

<ul>
<li><p><b>Zhe Wang</b>, H. Li, Q. Zhang, J. Yuan, X. Wang.
<a href="./welcome_files/papers/CSMRFML.pdf">"Magnetic Resonance Fingerprinting with Compressed Sensing and Distance Metric Learning"</a>, Journal of Neurocomputing, 2016.
</p>
</li>
</ul>

<ul>
<li><p>W. Ouyang, X. Wang, X. Zeng, S. Qiu, P. Luo, Y. Tian, H. Li, S. Yang, <b>Zhe Wang</b>, C. Loy, X. Tang.
<a href="./welcome_files/papers/deepidcvpr.pdf">"DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection"</a>, In Proc. CVPR 2015.
</p>
<p><a href="http://www.ee.cuhk.edu.hk/~wlouyang/projects/ImageNet/index.html">Models & Code</a></p></li>
</ul>

<ul>
<li><p>W. Ouyang, X. Wang, X. Zeng, S. Qiu, P. Luo, Y. Tian, H. Li, S. Yang, <b>Zhe Wang</b>, C. Loy, X. Tang.
<a href="./welcome_files/papers/deepidarxiv.pdf">"Deepid-net: multi-stage and deformable deep convolutional neural networks for object detection"</a>, Preprint, arXiv:1409.3505.
</p>
</ul>

<ul>
<li><p><b>Zhe Wang</b>, Q. Zhang, J. Yuan, X. Wang.
<a href="./welcome_files/papers/isbi.pdf">"MRF denoising with compressed sensing and adaptive filtering"</a>, IEEE 11th International Symposium on Biomedical Imaging (ISBI),  2014. <a href="./welcome_files/papers/ISBI_poster.pdf">(poster)</a>
</p>
</ul>



<h2>  Professional Activities </h2>
<ul>
  <li>
  <p>Reviewer of the following journals:</p> 
  <p><a href = "https://www.journals.elsevier.com/medical-image-analysis/">Medical Image Analysis (MIA)</a></p>
  <p><a href = "https://tbme.embs.org">IEEE Transactions on Biomedical Engineering (TBME)</a></p>
  <p><a href = "https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</a></p>
  </li>


  <li>
  <p>Reviewer of the following conferences:</p>
  <p><a href = "http://miccai2018.org/en/">International Conference on Medical Image Computing and Computer Assisted Intervention (ICCV 2019).</a></p>
  <p><a href = "http://miccai2018.org/en/">International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2019).</a></p>
  <p><a href = "http://miccai2018.org/en/">International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2018).</a></p>
  <p><a href = "http://www.vcip2017.org//">IEEE Visual Communications and Image Processing (VCIP 2017).</a></p>
  </li>
  </ul>


<!-- This is a comment
     </ul>

<h2> Teaching Experience </h2>


<ul>
<li>ENGG5202</li> Pattern Recognition
</ul>
<ul>
<li>ENGG1110</li> Problem Solving by Programming
</ul>
<ul>
<li>BMEG4320</li> Biomedical Imaging Applications
</ul>
<ul>
<li>ELEG2202</li> Circuit and Device
</ul>
<ul>
<li>ENGG1110B</li> Basic Circuit Theory
</ul> -->

<br>
<div><a href="http://info.flagcounter.com/Gjat"><img src="http://s10.flagcounter.com/count/Gjat/bg_FFFFFF/txt_000000/border_CCCCCC/columns_3/maxflags_12/viewers_0/labels_1/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0" align="middle"></a>
</div>

<div id="footer">
<div id="footer-text">


</div>

</div>
</div>
</body></html>

